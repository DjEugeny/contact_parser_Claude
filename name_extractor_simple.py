#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import re
import imaplib
import email
import ssl
import os
from dotenv import load_dotenv
from datetime import datetime, timedelta
from typing import List, Dict
import time
import logging
import sys

load_dotenv()

# üìù –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø
log_filename = 'name_extractor_simple_log.txt'
if os.path.exists(log_filename):
    os.remove(log_filename)

logging.basicConfig(
    level=logging.INFO,
    format='%(message)s',
    handlers=[
        logging.FileHandler(log_filename, encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger('name_extractor_simple')

class NameExtractorSimple:
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –§–ò–û —Å –æ–¥–Ω–∏–º —Ñ–∞–π–ª–æ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–π"""
    
    def __init__(self):
        self.imap_server = os.environ.get('IMAP_SERVER')
        self.imap_port = int(os.environ.get('IMAP_PORT', 143))
        self.imap_user = os.environ.get('IMAP_USER')
        self.imap_password = os.environ.get('IMAP_PASSWORD')
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É data –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        if not os.path.exists('data'):
            os.makedirs('data')
        
        # üìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞
        self.name_patterns = self._load_patterns_from_file()
        
        # üìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –ï–î–ò–ù–´–ô —Ñ–∞–π–ª –∏—Å–∫–ª—é—á–µ–Ω–∏–π
        self.exclusions = self._load_exclusions_from_file()
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–∞–ª–∏—á–∏—è –§–ò–û
        self.name_indicators = [
            '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å', '–¥–∏—Ä–µ–∫—Ç–æ—Ä', '–º–µ–Ω–µ–¥–∂–µ—Ä', '—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç',
            '–∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—å', '–Ω–∞—á–∞–ª—å–Ω–∏–∫', '–∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å', '–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π',
            '–∫–æ–Ω—Ç–∞–∫—Ç–Ω–æ–µ –ª–∏—Ü–æ', '–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å', '–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä',
            '–æ—Ç:', '—Å —É–≤–∞–∂–µ–Ω–∏–µ–º', '–ø–æ–¥–ø–∏—Å—å', '–∏—Å–ø.', '—Ç–µ–ª.', '–º–æ–±.'
        ]
        
        # üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º pymorphy2 –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–∞–¥–µ–∂–µ–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        try:
            import pymorphy2
            self.morph = pymorphy2.MorphAnalyzer()
            self.morphology_available = True
            logger.info("‚úÖ pymorphy2 –∑–∞–≥—Ä—É–∂–µ–Ω –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–∞–¥–µ–∂–µ–π")
        except ImportError:
            self.morph = None
            self.morphology_available = False
            logger.warning("‚ö†Ô∏è pymorphy2 –Ω–µ –Ω–∞–π–¥–µ–Ω. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–¥–µ–∂–µ–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        
        logger.info("‚úÖ –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –§–ò–û –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        logger.info(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {len(self.name_patterns)}")
        logger.info(f"üö´ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏—Å–∫–ª—é—á–µ–Ω–∏–π: {len(self.exclusions)}")
    
    def _load_patterns_from_file(self) -> List[str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞"""
        patterns_file = 'data/name_patterns.txt'
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏ –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        if not os.path.exists(patterns_file):
            default_patterns = [
                r'\b([–ê-–Ø–Å][–∞-—è—ë]{2,20}\s[–ê-–Ø–Å][–∞-—è—ë]{2,20}\s[–ê-–Ø–Å][–∞-—è—ë]{2,20})\b',
                r'\b([–ê-–Ø–Å][–∞-—è—ë]{2,20}\s[–ê-–Ø–Å][–∞-—è—ë]{2,20})\b',
                r'\b([–ê-–Ø–Å][–∞-—è—ë]{2,20}\s[–ê-–Ø–Å]\.)\b',
                r'\b([–ê-–Ø–Å][–∞-—è—ë]{2,20}\s[–ê-–Ø–Å]\.\s*[–ê-–Ø–Å]\.)\b',
                r'\b([–ê-–Ø–Å]\.?\s*[–ê-–Ø–Å]\.?\s*[–ê-–Ø–Å][–∞-—è—ë]{2,20})\b',
                r'\b([–ê-–Ø–Å]\.?\s*[–ê-–Ø–Å][–∞-—è—ë]{2,20})\b'
            ]
            with open(patterns_file, 'w', encoding='utf-8') as f:
                for pattern in default_patterns:
                    f.write(pattern + '\n')
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        patterns = []
        try:
            with open(patterns_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        patterns.append(line)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {e}")
            patterns = [r'\b([–ê-–Ø–Å][–∞-—è—ë]+\s[–ê-–Ø–Å][–∞-—è—ë]+)\b']
        
        return patterns
    
    def _load_exclusions_from_file(self) -> set:
        """üîß –£–ü–†–û–©–ï–ù–û: –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∏–∑ –û–î–ù–û–ì–û —Ñ–∞–π–ª–∞"""
        exclusions_file = 'data/exclusions.txt'
        exclusions = set()
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –∏—Å–∫–ª—é—á–µ–Ω–∏–π –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        if not os.path.exists(exclusions_file):
            default_exclusions = [
                '# –í—Å–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –¥–ª—è –§–ò–û –≤ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ',
                '# –ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –æ–±—ä–µ–∫—Ç—ã',
                '—É–ª–∏—Ü–∞', '—É–ª.', '–ø—Ä–æ—Å–ø–µ–∫—Ç', '–ø—Ä.', '–ø–µ—Ä–µ—É–ª–æ–∫', '–ø–µ—Ä.',
                '–ø–ª–æ—â–∞–¥—å', '–ø–ª.', '–±—É–ª—å–≤–∞—Ä', '–±-—Ä', '—à–æ—Å—Å–µ', '–Ω–∞–±–µ—Ä–µ–∂–Ω–∞—è',
                '–∞–Ω–¥—Ä–∏–µ–Ω–∞ –ª–µ–∂–µ–Ω–∞', '–ª–µ–∂–µ–Ω–∞',
                '# –î–æ–ª–∂–Ω–æ—Å—Ç–∏',
                '–¥–∏—Ä–µ–∫—Ç–æ—Ä', '–º–µ–Ω–µ–¥–∂–µ—Ä', '—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç', '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å',
                '–≤–µ–¥—É—â–∏–π', '—Å—Ç–∞—Ä—à–∏–π', '–≥–ª–∞–≤–Ω—ã–π', '–∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—å',
                '# –ö–æ–º–ø–∞–Ω–∏–∏',
                '–æ–æ–æ', '–∑–∞–æ', '–ø–∞–æ', '–∞–æ', '–∏–ø', '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è',
                '–¥–Ω–∞-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è', '–¥–Ω–∫-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è', '–±–∏–æ—Ö–∏–º–º–∞–∫',
                '# –û–±—â–∏–µ —Å–ª–æ–≤–∞',
                '—Å–∏—Å—Ç–µ–º–∞', '–æ—Ç–¥–µ–ª', '–¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç', '–∫–æ–º–ø–∞–Ω–∏—è'
            ]
            
            with open(exclusions_file, 'w', encoding='utf-8') as f:
                for item in default_exclusions:
                    f.write(item + '\n')
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏—è
        try:
            with open(exclusions_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip().lower()
                    if line and not line.startswith('#'):
                        exclusions.add(line)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å–∫–ª—é—á–µ–Ω–∏—è: {e}")
        
        return exclusions
    
    def _normalize_name_morphology(self, name: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –§–ò–û –≤ –∏–º–µ–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞–¥–µ–∂"""
        if not self.morphology_available:
            return name
        
        words = name.split()
        normalized_words = []
        
        for word in words:
            try:
                parsed = self.morph.parse(word)[0]
                if any(tag in str(parsed.tag) for tag in ['Name', 'Surn', 'Patr']) or parsed.tag.POS in ['NOUN']:
                    nominative = parsed.inflect({'nomn'})
                    if nominative:
                        normalized_words.append(nominative.word.capitalize())
                    else:
                        normalized_words.append(parsed.normal_form.capitalize())
                else:
                    normalized_words.append(word.capitalize())
            except Exception:
                normalized_words.append(word.capitalize())
        
        return ' '.join(normalized_words)
    
    def extract_names_only(self, text: str) -> List[Dict[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –§–ò–û –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π"""
        
        if not text or not isinstance(text, str):
            return []
        
        text = text[:15000]
        processed_text = self._preprocess_text(text)
        raw_names = self._extract_by_patterns(processed_text)
        filtered_names = self._filter_names_simple(raw_names, processed_text)
        final_names = self._normalize_and_deduplicate_simple(filtered_names)
        
        return final_names
    
    def _preprocess_text(self, text: str) -> str:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
        text = re.sub(r'\s+', ' ', text)
        text = text.replace('\n', ' ').replace('\r', ' ')
        text = text.replace('—ë', '–µ').replace('–Å', '–ï')
        return text.strip()
    
    def _extract_by_patterns(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –§–ò–û –ø–æ regex –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º"""
        found_names = []
        for pattern in self.name_patterns:
            try:
                matches = re.findall(pattern, text)
                found_names.extend(matches)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –ø–∞—Ç—Ç–µ—Ä–Ω–µ {pattern}: {e}")
        return found_names
    
    def _filter_names_simple(self, raw_names: List[str], full_text: str) -> List[str]:
        """üîß –£–ü–†–û–©–ï–ù–ù–ê–Ø —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å –æ–¥–Ω–∏–º —Ñ–∞–π–ª–æ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–π"""
        
        filtered = []
        full_text_lower = full_text.lower()
        
        for name in raw_names:
            # üö´ –ï–¥–∏–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
            if self._is_excluded_simple(name):
                continue
            
            # ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–ª–∏ –æ—á–µ–≤–∏–¥–Ω–æ—Å—Ç—å –§–ò–û
            if self._has_name_context(name, full_text_lower) or self._looks_like_name(name):
                filtered.append(name)
        
        return filtered
    
    def _is_excluded_simple(self, name: str) -> bool:
        """üîß –£–ü–†–û–©–ï–ù–û: –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π –∏–∑ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
        
        name_lower = name.lower()
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if name_lower in self.exclusions:
            return True
        
        # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –¥–ª—è —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π
        for exclusion in self.exclusions:
            if len(exclusion.split()) > 1:
                if exclusion in name_lower:
                    return True
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–ª–æ–≤ –≤ —Å–æ—Å—Ç–∞–≤–µ –§–ò–û
        words = name_lower.split()
        for word in words:
            if word in self.exclusions:
                return True
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        if len(name) > 100 or re.search(r'\d', name) or re.search(r'[a-zA-Z]', name):
            return True
        
        return False
    
    def _has_name_context(self, name: str, full_text_lower: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç"""
        name_lower = name.lower()
        name_pos = full_text_lower.find(name_lower)
        if name_pos == -1:
            return False
        
        context_start = max(0, name_pos - 100)
        context_end = min(len(full_text_lower), name_pos + len(name_lower) + 100)
        context = full_text_lower[context_start:context_end]
        
        for indicator in self.name_indicators:
            if indicator in context:
                return True
        return False
    
    def _looks_like_name(self, name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—Ö–æ–∂–µ—Å—Ç—å –Ω–∞ –§–ò–û"""
        if re.search(r'[–ê-–Ø–Å]\.', name):
            return True
        if len(name.split()) == 3:
            return True
        
        words = name.split()
        if len(words) == 2:
            if all(len(word) >= 2 for word in words):
                if all(word[0].isupper() for word in words):
                    if not re.search(r'[0-9a-zA-Z]', name):
                        return True
        return False
    
    def _normalize_and_deduplicate_simple(self, names: List[str]) -> List[Dict[str, str]]:
        """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è"""
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–∞–¥–µ–∂–∏
        normalized_names = []
        for name in names:
            normalized_name = self._normalize_name_morphology(name)
            normalized_names.append(normalized_name)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∏ –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ–º
        full_names = []
        short_names = []
        
        for name in normalized_names:
            words = name.split()
            if len(words) == 3 and not re.search(r'[–ê-–Ø–Å]\.', name):
                full_names.append(name)
            else:
                short_names.append(name)
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç
        result_names = []
        seen = set()
        
        # –ü–æ–ª–Ω—ã–µ –∏–º–µ–Ω–∞
        for full_name in full_names:
            if full_name not in seen:
                result_names.append({'fullname': full_name, 'type': 'full_name'})
                seen.add(full_name)
        
        # –°–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–µ (–±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ–ª–Ω—ã—Ö)
        for short_name in short_names:
            if short_name not in seen:
                is_duplicate = False
                short_words = short_name.split()
                
                for full_name in full_names:
                    full_words = full_name.split()
                    if len(short_words) >= 2 and len(full_words) >= 2:
                        if (short_words[0].lower() == full_words[0].lower() and 
                            short_words[1].lower() == full_words[1].lower()):
                            is_duplicate = True
                            break
                
                if not is_duplicate:
                    result_names.append({
                        'fullname': short_name,
                        'type': self._classify_name_type(short_name)
                    })
                    seen.add(short_name)
        
        return result_names
    
    def _classify_name_type(self, name: str) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–∞ –§–ò–û"""
        if re.search(r'[–ê-–Ø–Å]\.\s*[–ê-–Ø–Å]\.', name):
            return 'with_two_initials'
        elif re.search(r'[–ê-–Ø–Å]\.', name):
            return 'with_one_initial'
        elif len(name.split()) == 3:
            return 'full_name'
        elif len(name.split()) == 2:
            return 'name_surname'
        else:
            return 'unknown'
    
    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è —Ç–∞–∫–∏–º–∏ –∂–µ
    def _extract_email_body_fast(self, msg) -> str:
        """–ë—ã—Å—Ç—Ä–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–ª–∞ –ø–∏—Å—å–º–∞"""
        body = ""
        max_size = 15000
        
        try:
            if msg.is_multipart():
                for part in msg.walk():
                    if part.get_content_type() == "text/plain":
                        charset = part.get_content_charset() or 'utf-8'
                        try:
                            payload = part.get_payload(decode=True)
                            if payload:
                                content = payload.decode(charset, errors="ignore")
                                body = content[:max_size]
                                break
                        except Exception:
                            continue
            else:
                charset = msg.get_content_charset() or 'utf-8'
                try:
                    payload = msg.get_payload(decode=True)
                    if payload:
                        content = payload.decode(charset, errors="ignore")
                        body = content[:max_size]
                except Exception:
                    body = ""
        except Exception:
            body = ""
        
        return body.strip()
    
    def _decode_header_clean(self, header_str: str) -> str:
        """–î–µ–∫–æ–¥–∏—Ä—É–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ø–æ—á—Ç—ã"""
        if not header_str:
            return ""
        try:
            from email.header import decode_header, make_header
            decoded = str(make_header(decode_header(header_str)))
            return decoded
        except:
            return header_str
    
    def _parse_email_date(self, date_str: str) -> str:
        """–ü–∞—Ä—Å–∏—Ç –¥–∞—Ç—É –ø–∏—Å—å–º–∞"""
        if not date_str:
            return "–î–∞—Ç–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞"
        try:
            dt = email.utils.parsedate_to_datetime(date_str)
            dt_adjusted = dt.replace(tzinfo=None) + timedelta(hours=4)
            return dt_adjusted.strftime('%d.%m.%Y %H:%M')
        except Exception:
            return date_str[:16] if len(date_str) > 16 else date_str
    
    def test_single_date_detailed(self, date_str: str = '2025-07-29'):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –æ–¥–Ω—É –¥–∞—Ç—É"""
        logger.info("=" * 80)
        logger.info(f"üìù –£–ü–†–û–©–ï–ù–ù–´–ô –¢–ï–°–¢ –§–ò–û –ó–ê {date_str}")
        logger.info("=" * 80)
        
        try:
            logger.info(f"üîå –ü–æ–¥–∫–ª—é—á–∞—é—Å—å –∫ {self.imap_server}...")
            
            mailbox = imaplib.IMAP4(self.imap_server, self.imap_port)
            mailbox.starttls(ssl.create_default_context())
            mailbox.login(self.imap_user, self.imap_password)
            mailbox.select('INBOX')
            
            dt = datetime.strptime(date_str, '%Y-%m-%d')
            imap_date = dt.strftime('%d-%b-%Y')
            criteria = f'(ON "{imap_date}")'
            
            status, data = mailbox.search(None, criteria)
            mail_ids = data[0].split() if status == 'OK' else []
            
            total_emails = len(mail_ids)
            logger.info(f"üì¨ –í—Å–µ–≥–æ –ø–∏—Å–µ–º –∑–∞ {date_str}: {total_emails}")
            
            if total_emails == 0:
                logger.info("‚ùå –ü–∏—Å–µ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
                mailbox.logout()
                return {'date': date_str, 'total_emails': 0, 'emails_with_names': 0, 'unique_names': 0, 'names_list': []}
            
            emails_with_names = []
            all_names = []
            start_time = time.time()
            
            for i, mail_id in enumerate(mail_ids, 1):
                try:
                    status, msg_data = mailbox.fetch(mail_id, '(RFC822)')
                    if status != 'OK':
                        continue
                    
                    raw_email = msg_data[0][1]
                    msg = email.message_from_bytes(raw_email)
                    
                    subject = self._decode_header_clean(msg.get('Subject', '–ë–µ–∑ —Ç–µ–º—ã'))
                    from_addr = self._decode_header_clean(msg.get('From', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'))
                    email_date = self._parse_email_date(msg.get('Date', ''))
                    
                    body = self._extract_email_body_fast(msg)
                    names = self.extract_names_only(body)
                    
                    if names:
                        email_info = {
                            'number': i,
                            'subject': subject,
                            'from': from_addr,
                            'date': email_date,
                            'names': names
                        }
                        emails_with_names.append(email_info)
                        all_names.extend(names)
                        
                        logger.info(f"\nüìß –ü–∏—Å—å–º–æ {i}/{total_emails}: {email_date}")
                        logger.info(f"   üìù –¢–µ–º–∞: {subject}")
                        logger.info(f"   üë§ –û—Ç: {from_addr}")
                        logger.info("   üìù –§–ò–û:")
                        for name_info in names:
                            logger.info(f"      ‚úÖ {name_info['fullname']} ({name_info['type']})")
                
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∏—Å—å–º–∞ {i}: {e}")
                    continue
            
            mailbox.logout()
            
            unique_names = []
            seen_names = set()
            for name_info in all_names:
                if name_info['fullname'] not in seen_names:
                    unique_names.append(name_info)
                    seen_names.add(name_info['fullname'])
            
            total_time = time.time() - start_time
            
            logger.info("=" * 80)
            logger.info(f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –£–ü–†–û–©–ï–ù–ù–û–ì–û –¢–ï–°–¢–ê –ó–ê {date_str}")
            logger.info("=" * 80)
            logger.info(f"üì¨ –í—Å–µ–≥–æ –ø–∏—Å–µ–º: {total_emails}")
            logger.info(f"üìù –ü–∏—Å–µ–º —Å –§–ò–û: {len(emails_with_names)}")
            logger.info(f"üéØ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –§–ò–û: {len(unique_names)}")
            logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_time:.1f} —Å–µ–∫")
            
            if unique_names:
                logger.info(f"\nüìã –í–°–ï –£–ù–ò–ö–ê–õ–¨–ù–´–ï –§–ò–û –ó–ê {date_str}:")
                for i, name_info in enumerate(sorted(unique_names, key=lambda x: x['fullname']), 1):
                    logger.info(f"   {i:2d}. {name_info['fullname']} ({name_info['type']})")
            
            logger.info("=" * 80)
            logger.info(f"‚úÖ –£–ü–†–û–©–ï–ù–ù–´–ô –¢–ï–°–¢ –ó–ê {date_str} –ó–ê–í–ï–†–®–ï–ù")
            logger.info("=" * 80)
            
            return {
                'date': date_str,
                'total_emails': total_emails,
                'emails_with_names': len(emails_with_names),
                'unique_names': len(unique_names),
                'names_list': unique_names,
                'detailed_results': emails_with_names
            }
            
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è {date_str}: {e}")
            return None
    
    def test_date_range_detailed(self, start_date: str, end_date: str):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç"""
        logger.info("=" * 80)
        logger.info(f"üìù –£–ü–†–û–©–ï–ù–ù–´–ô –¢–ï–°–¢ –§–ò–û –ü–û –î–ò–ê–ü–ê–ó–û–ù–£: {start_date} - {end_date}")
        logger.info("=" * 80)
        
        start_dt = datetime.strptime(start_date, '%Y-%m-%d')
        end_dt = datetime.strptime(end_date, '%Y-%m-%d')
        current_date = start_dt
        
        total_emails_all = 0
        total_names_all = []
        all_daily_results = []
        total_days = (end_dt - start_dt).days + 1
        
        day_counter = 1
        while current_date <= end_dt:
            date_str = current_date.strftime('%Y-%m-%d')
            
            logger.info(f"\nüéØ –î–ï–ù–¨ {day_counter}/{total_days}: {date_str}")
            logger.info("=" * 50)
            
            daily_results = self.test_single_date_detailed(date_str)
            
            if daily_results:
                total_emails_all += daily_results['total_emails']
                total_names_all.extend(daily_results['names_list'])
                all_daily_results.append(daily_results)
            else:
                logger.info(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞—Ç—ã {date_str}")
            
            current_date += timedelta(days=1)
            day_counter += 1
        
        unique_names_all = []
        seen_names_all = set()
        for name_info in total_names_all:
            if name_info['fullname'] not in seen_names_all:
                unique_names_all.append(name_info)
                seen_names_all.add(name_info['fullname'])
        
        logger.info("=" * 80)
        logger.info(f"üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –£–ü–†–û–©–ï–ù–ù–û–ì–û –¢–ï–°–¢–ê {start_date} - {end_date}")
        logger.info("=" * 80)
        logger.info(f"üìÖ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–Ω–µ–π: {total_days}")
        logger.info(f"üì¨ –í—Å–µ–≥–æ –ø–∏—Å–µ–º: {total_emails_all}")
        logger.info(f"üéØ –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –§–ò–û: {len(unique_names_all)}")
        
        if unique_names_all:
            logger.info(f"\nüìã –í–°–ï –§–ò–û –ó–ê –ü–ï–†–ò–û–î {start_date} - {end_date}:")
            for i, name_info in enumerate(sorted(unique_names_all, key=lambda x: x['fullname']), 1):
                logger.info(f"   {i:3d}. {name_info['fullname']} ({name_info['type']})")
            
            logger.info("\nüìä –ö–†–ê–¢–ö–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –î–ù–Ø–ú:")
            for day_result in all_daily_results:
                if day_result['emails_with_names'] > 0:
                    logger.info(f"   üìÖ {day_result['date']}: {day_result['total_emails']} –ø–∏—Å–µ–º, {day_result['emails_with_names']} —Å –§–ò–û, {day_result['unique_names']} —É–Ω–∏–∫.")
                else:
                    logger.info(f"   üìÖ {day_result['date']}: {day_result['total_emails']} –ø–∏—Å–µ–º, –§–ò–û –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        logger.info("=" * 80)
        logger.info(f"‚úÖ –£–ü–†–û–©–ï–ù–ù–´–ô –¢–ï–°–¢ –î–ò–ê–ü–ê–ó–û–ù–ê –ó–ê–í–ï–†–®–ï–ù")
        logger.info("=" * 80)
        
        return {
            'start_date': start_date,
            'end_date': end_date,
            'total_days': total_days,
            'total_emails': total_emails_all,
            'total_unique_names': len(unique_names_all),
            'all_names': unique_names_all,
            'daily_results': all_daily_results
        }


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —É–ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–µ—Ä–∞"""
    
    logger.info("üöÄ –ó–ê–ü–£–°–ö –£–ü–†–û–©–ï–ù–ù–û–ì–û –¢–ï–°–¢–ï–†–ê –§–ò–û")
    
    tester = NameExtractorSimple()
    
    # üéØ –ù–ê–°–¢–†–û–ô–ö–ê –î–ê–¢ - –ò–ó–ú–ï–ù–ò –ó–î–ï–°–¨! (—Å—Ç—Ä–æ–∫–∏ 378-379)
    start_date = '2025-07-29'  # ‚Üê –ù–ê–ß–ê–õ–¨–ù–ê–Ø –î–ê–¢–ê
    end_date = '2025-08-04'    # ‚Üê –ö–û–ù–ï–ß–ù–ê–Ø –î–ê–¢–ê
    
    results = tester.test_date_range_detailed(start_date, end_date)
    
    if results:
        logger.info(f"\nüéâ –£–ü–†–û–©–ï–ù–ù–´–ô –¢–ï–°–¢ –§–ò–û –ó–ê–í–ï–†–®–ï–ù!")
        logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥: {results['start_date']} - {results['end_date']}")
        logger.info(f"üì¨ –í—Å–µ–≥–æ –ø–∏—Å–µ–º: {results['total_emails']}")
        logger.info(f"üìù –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –§–ò–û: {results['total_unique_names']}")


if __name__ == "__main__":
    main()
